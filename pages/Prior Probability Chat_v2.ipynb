{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a88a309e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.factors.discrete.CPD import TabularCPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "227763c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai.api_key = \"YOUR_API_KEY\"\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b976da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bold Text fuction when printing\n",
    "def bold_text(text):\n",
    "    return \"\\033[1m\" + text + \"\\033[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c825cacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_nodes = [node for node in missing_node_list if node not in unique_events]\n",
    "\n",
    "# for edge in missing_nodes:\n",
    "#     node_a = edge[0]\n",
    "#     node_b = edge[1]\n",
    "#     value_a = conversation_data.get('triggers', {}).get(node_a) or conversation_data.get('mitigators', {}).get(node_a)\n",
    "#     value_b = conversation_data.get('events', {}).get(node_b) or conversation_data.get('consequences', {}).get(node_b)\n",
    "#     missing_nodes_name.append([value_a, value_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64b3b180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember do not mix the main questions and follow-up questions!\n",
    "missing_nodes_name = ['buying straddles'] #change to Hedging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9131dd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "\u001b[1mChatGPT:\u001b[0m Q1. Probability of which state is lower: \"Low\" or \"Medium\" for ['buying straddles']?\n",
      "low\n",
      "\u001b[1mChatGPT:\u001b[0m Q2. If relative weight of 'low' is 1, what is the relative weight of 'medium'?\n",
      "maybe 3\n",
      "\u001b[1mChatGPT:\u001b[0m Q3. Probability of which state is lower: \"Medium\" or \"High\" for ['buying straddles']?\n",
      "medium\n",
      "\u001b[1mChatGPT:\u001b[0m Q4. If relative weight of 'medium' is 1, what is the relative weight of 'high'?\n",
      "4\n",
      "\u001b[1mChatGPT:\u001b[0m Q5. Probability of which state is lower: \"Low\" or \"High\" for ['buying straddles']?\n",
      "low\n",
      "\u001b[1mChatGPT:\u001b[0m Q6. If relative weight of 'low' is 1, what is the relative weight of 'high'?\n",
      "not sure, any suggestion?\n",
      "\u001b[1mChatGPT:\u001b[0m If you're unsure of the relative weight between \"low\" and \"high\" for ['buying straddles'], let's assume it as 2 for now. This means if the relative weight of \"low\" is 1, the relative weight of \"high\" would be 2.\n",
      "\n",
      "Please summarize the information as follows:\n",
      "\n",
      "low_mid = 3\n",
      "mid_high = 4\n",
      "low_high = 2\n",
      "quit\n"
     ]
    }
   ],
   "source": [
    "template = f\"\"\"\n",
    "I want you to act as a person collecting information on the probability and relative weight.\n",
    "Ask questions one at a time, sequentially! Wait for my answer before moving on to the next question.\n",
    "\n",
    "Below is the instruction on asking questions.\n",
    "Q1. Probability of which state is lower: \"Low\" or \"Medium\" for {missing_nodes_name}?\n",
    "Q2. The follow-up question you should ask is;\n",
    "If the answer is \"low\", ask \n",
    "\"If relative weight of 'low' is 1, what is the relative weight of 'medium'?\". \n",
    "If the answer is \"medium\", ask \n",
    "\"If relative weight of 'medium' is 1, what is the relative weight of 'low'?\"\n",
    "\n",
    "Q3. Probability of which state is lower: \"Medium\" or \"High\" for {missing_nodes_name}?\n",
    "Q4. The follow-up question you should ask is;\n",
    "If the answer is \"medium\", ask \n",
    "\"If relative weight of 'medium' is 1, what is the relative weight of 'high'?\". \n",
    "If the answer is \"high\", ask \n",
    "\"If relative weight of 'high' is 1, what is the relative weight of 'medium'?\"\n",
    "\n",
    "Q5. Probability of which state is lower: \"Low\" or \"High\" for {missing_nodes_name}?\n",
    "Q6.The follow-up question you should ask is;\n",
    "If the answer is \"low\", ask \n",
    "\"If relative weight of 'low' is 1, what is the relative weight of 'high'?\". \n",
    "If the answer is \"high\", ask \n",
    "\"If relative weight of 'high' is 1, what is the relative weight of 'low'?\"\n",
    "\n",
    "After you've collected all the information on relative weight value, summarize it as follows; \n",
    "\n",
    "low_mid = Relative weight numeric value from Q2\n",
    "mid_high = Relative weight numeric value from Q4\n",
    "low_high = Relative weight numeric value from Q6\n",
    "\n",
    "An example summary is as follows;\n",
    "low_mid = 1.5\n",
    "mid_high = 4\n",
    "low_high = 7\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "chat_log = []\n",
    "\n",
    "while True:\n",
    "    user_message = input()\n",
    "    if user_message.lower() == \"quit\":\n",
    "        break\n",
    "    else:\n",
    "        chat_log.append({\"role\": \"user\", \"content\": user_message})\n",
    "        # Append the template as a system message in the chat log\n",
    "        chat_log.append({\"role\": \"system\", \"content\": template})\n",
    "        \n",
    "        response = openai.ChatCompletion.create(\n",
    "            model= \"gpt-3.5-turbo-16k-0613\",\n",
    "            messages=chat_log,\n",
    "            temperature=0.8\n",
    "        )\n",
    "\n",
    "        assistant_response = response['choices'][0]['message']['content']\n",
    "        print(bold_text(\"ChatGPT:\"), assistant_response.strip(\"\\n\").strip())\n",
    "        chat_log.append({\"role\": \"assistant\", \"content\" : assistant_response.strip(\"\\n\").strip()})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffc998a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "\u001b[1mChatGPT:\u001b[0m Q1. Probability of which state is lower: \"low\" or \"medium\" for ['buying straddles']?\n",
      "low\n",
      "\u001b[1mChatGPT:\u001b[0m Q2. If the relative weight of \"low\" is 1, what is the relative weight of \"medium\"?\n",
      "2\n",
      "\u001b[1mChatGPT:\u001b[0m Q3. Probability of which state is lower: \"medium\" or \"high\" for ['buying straddles']?\n",
      "medium\n",
      "\u001b[1mChatGPT:\u001b[0m Q4. If the relative weight of \"medium\" is 1, what is the relative weight of \"high\"?\n",
      "2\n",
      "\u001b[1mChatGPT:\u001b[0m Q5. Probability of which state is lower: \"low\" or \"high\" for ['buying straddles']?\n",
      "low\n",
      "\u001b[1mChatGPT:\u001b[0m Q6. If the relative weight of \"low\" is 1, what is the relative weight of \"high\"?\n",
      "6\n",
      "\u001b[1mChatGPT:\u001b[0m Summary:\n",
      "low_mid = 2\n",
      "mid_high = 2\n",
      "low_high = 6\n",
      "quit\n"
     ]
    }
   ],
   "source": [
    "template = f\"\"\"\n",
    "I want you to act as a person collecting information on the probability and relative weight.\n",
    "Ask questions one at a time, sequentially!\n",
    "Wait for my answer before moving on to the next question.\n",
    "\n",
    "Below is the instruction on asking questions.\n",
    "Q1. Probability of which state is lower: \"low\" or \"medium\" for {missing_nodes_name}?\n",
    "Q2. The follow-up question you should ask is;\n",
    "Based on the lower probability state, you should ask \n",
    "\"If relative weight of (previous answer) is 1, what is the relative weight of (opposite of previous answer)?\". \n",
    "\n",
    "Q3. Probability of which state is lower: \"medium\" or \"high\" for {missing_nodes_name}?\n",
    "Q4. The follow-up question you should ask is;\n",
    "Based on the lower probability state, you should ask \n",
    "\"If relative weight of (previous answer) is 1, what is the relative weight of (opposite of previous answer)?\". \n",
    "\n",
    "Q5. Probability of which state is lower: \"low\" or \"high\" for {missing_nodes_name}?\n",
    "Q6. The follow-up question you should ask is;\n",
    "Based on the lower probability state, you should ask \n",
    "\"If relative weight of (previous answer) is 1, what is the relative weight of (opposite of previous answer)?\". \n",
    "\n",
    "\n",
    "After you've collected all the information on relative weight value, summarize as follows:\n",
    "low_mid = Relative weight numeric value from Q2\n",
    "mid_high = Relative weight numeric value from Q4\n",
    "low_high = Relative weight numeric value from Q6\n",
    "\n",
    "An example summary is as follows;\n",
    "low_mid = 1.5\n",
    "mid_high = 4\n",
    "low_high = 7\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "chat_log = []\n",
    "\n",
    "while True:\n",
    "    user_message = input()\n",
    "    if user_message.lower() == \"quit\":\n",
    "        break\n",
    "    else:\n",
    "        chat_log.append({\"role\": \"user\", \"content\": user_message})\n",
    "        # Append the template as a system message in the chat log\n",
    "        chat_log.append({\"role\": \"system\", \"content\": template})\n",
    "        \n",
    "        response = openai.ChatCompletion.create(\n",
    "            model= \"gpt-3.5-turbo-16k-0613\",\n",
    "            messages=chat_log,\n",
    "            temperature=0.5 #0.3\n",
    "        )\n",
    "\n",
    "        assistant_response = response['choices'][0]['message']['content']\n",
    "        print(bold_text(\"ChatGPT:\"), assistant_response.strip(\"\\n\").strip())\n",
    "        chat_log.append({\"role\": \"assistant\", \"content\" : assistant_response.strip(\"\\n\").strip()})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba179156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_max_eigenvector(assistant_response):\n",
    "    numeric_values = [float(value) for value in re.findall(r\"=\\s(\\d+\\.\\d+|\\d+)\", assistant_response)]\n",
    "\n",
    "    nested_array = [\n",
    "        [1, numeric_values[0], numeric_values[2]],\n",
    "        [1/numeric_values[0], 1, numeric_values[1]],\n",
    "        [1/numeric_values[2], 1/numeric_values[1], 1]\n",
    "    ]\n",
    "\n",
    "    matrix = np.array(nested_array)\n",
    "    \n",
    "    eigenvalues, eigenvectors = np.linalg.eig(matrix)\n",
    "\n",
    "    max_eigenvalue_index = np.argmax(eigenvalues)\n",
    "    max_eigenvalue = eigenvalues[max_eigenvalue_index]\n",
    "\n",
    "    max_eigenvector = np.real(eigenvectors[:, max_eigenvalue_index])\n",
    "\n",
    "    # Normalize the eigenvector\n",
    "    max_eigenvector /= np.sum(max_eigenvector)\n",
    "    max_eigenvector_2d = np.array([[value] for value in max_eigenvector])\n",
    "    \n",
    "    # Calculate CR\n",
    "    n_1 = len(max_eigenvalue) \n",
    "    CI = (max_eigenvalue - n) / (n - 1)\n",
    "    RI = 0.58\n",
    "    CR = CI / RI\n",
    "    \n",
    "    matrices = []\n",
    "    CR_values = []\n",
    "\n",
    "    nested_array = [\n",
    "            [1, numeric_values[i], numeric_values[i+2]],\n",
    "            [1/numeric_values[i], 1, numeric_values[i+1]],\n",
    "            [1/numeric_values[i+2], 1/numeric_values[i+1], 1]\n",
    "        ]\n",
    "        \n",
    "    matrix = np.array(nested_array)\n",
    "    \n",
    "    eigenvalues, eigenvectors = np.linalg.eig(matrix)\n",
    "    max_eigenvalue_index = np.argmax(eigenvalues)\n",
    "    max_eigenvalue = eigenvalues[max_eigenvalue_index]\n",
    "    \n",
    "    max_eigenvector = np.real(eigenvectors[:, max_eigenvalue_index])\n",
    "    max_eigenvector /= np.sum(max_eigenvector)\n",
    "    max_eigenvector_2d = np.array([[value] for value in max_eigenvector])\n",
    "\n",
    "    n = matrix.shape[0]  # Get the size of the matrix (number of rows/columns)\n",
    "    CI = np.abs(max_eigenvalue - n) / (n - 1)  # Use the absolute value for complex numbers\n",
    "    RI = 0.58\n",
    "    CR = CI / RI\n",
    "    \n",
    "    matrices.append(max_eigenvector_2d)\n",
    "    CR_values.append(CR)\n",
    "\n",
    "    return matrices, CR_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18328f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.53166957],\n",
       "        [0.32203591],\n",
       "        [0.14629452]])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrices, CR_values = calculate_max_eigenvector(assistant_response)\n",
    "matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3002dd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"/Users/irislee/Uchicago Class Materials/4. 3Q/Capstone/Langchain/Chat\"\n",
    "file_name = \"prior_prob.json\"\n",
    "file_path = os.path.join(directory_path, file_name)\n",
    "\n",
    "# Convert the matrices ndarray to Python lists\n",
    "matrices_list = [matrix.tolist() for matrix in matrices]\n",
    "\n",
    "# Save the Python lists to a JSON file\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(matrices_list, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc946f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "| BS(0) | 0.53167  |\n",
      "+-------+----------+\n",
      "| BS(1) | 0.322036 |\n",
      "+-------+----------+\n",
      "| BS(2) | 0.146295 |\n",
      "+-------+----------+\n"
     ]
    }
   ],
   "source": [
    "BS_cpd = TabularCPD('BS', 3, matrices[0])\n",
    "print(BS_cpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e9e1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check if the matrix is acceptable based on CR\n",
    "# if CR <= 0.1:\n",
    "#     print(\"The matrix is acceptable.\")\n",
    "# else:\n",
    "#     print(\"The matrix is not acceptable.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
