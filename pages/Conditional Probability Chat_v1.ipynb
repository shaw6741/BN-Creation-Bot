{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88a309e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.factors.discrete.CPD import TabularCPD\n",
    "import numpy as np\n",
    "from scipy.stats import triang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "227763c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai.api_key = \"YOUR_API_KEY\"\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b976da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bold Text fuction when printing\n",
    "def bold_text(text):\n",
    "    return \"\\033[1m\" + text + \"\\033[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64b3b180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember do not mix the main questions and follow-up questions!\n",
    "missing_nodes_name = 'Hedging' #change to Hedging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9131dd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "\u001b[1mChatGPT:\u001b[0m Hello! I will be collecting information on the probability and relative weight for two different scenarios. Please keep in mind that the value of the probability should be between 0 and 1.\n",
      "\n",
      "Q1: Considering Hedging occurs and a 15% 'Investment loss' over 5 days, what do you think are the most likely lower limit, upper limit, and mode of the probability?\n",
      "\n",
      "Q2: Considering Hedging does not occur and a 15% 'Investment loss' over 5 days, what do you think are the most likely lower limit, upper limit, and mode of the probability?\n",
      "\n",
      "Please provide your answers one at a time, starting with Q1.\n",
      "quit\n"
     ]
    }
   ],
   "source": [
    "template = f\"\"\"\n",
    "I want you to act as a person collecting information on the probability and relative weight.\n",
    "\n",
    "Ask Q1 and Q2 questions one at a time, sequentially! Wait for the user's answer before moving on to the next question.\n",
    "\n",
    "Below is the instruction on asking questions. Below questions are two different questions.\n",
    "Q1. \"Considering {missing_nodes_name} occurs and a 15% 'Investment loss' over 5 days, what do you think are the most likely lower limit, upper limit, and mode of the probability?\"\n",
    "Q2. \"Considering {missing_nodes_name} does not occur and a 15% 'Investment loss' over 5 days, what do you think are the most likely lower limit, upper limit, and mode of the probability?\"\n",
    "\n",
    "Before asking, make sure to inform the user that value of the probability should be between 0 and 1!\n",
    "\n",
    "After you've collected all the information on relative weight value, summarize it as follows; \n",
    "\n",
    "Q1 = probability lower limit, upper limit, and the most likely value from Q1\n",
    "Q2 = probability lower limit, upper limit, and the most likely value from Q2\n",
    "\n",
    "An example summary is as follows;\n",
    "Q1 = 0.1, 0.3, 0.4\n",
    "Q2 = 0.2, 0.4, 0.3\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "chat_log = []\n",
    "\n",
    "while True:\n",
    "    user_message = input()\n",
    "    if user_message.lower() == \"quit\":\n",
    "        break\n",
    "    else:\n",
    "        chat_log.append({\"role\": \"user\", \"content\": user_message})\n",
    "        # Append the template as a system message in the chat log\n",
    "        chat_log.append({\"role\": \"system\", \"content\": template})\n",
    "        \n",
    "        response = openai.ChatCompletion.create(\n",
    "            model= \"gpt-3.5-turbo-16k-0613\",\n",
    "            messages=chat_log,\n",
    "            temperature=0.3\n",
    "        )\n",
    "\n",
    "        assistant_response = response['choices'][0]['message']['content']\n",
    "        print(bold_text(\"ChatGPT:\"), assistant_response.strip(\"\\n\").strip())\n",
    "        chat_log.append({\"role\": \"assistant\", \"content\" : assistant_response.strip(\"\\n\").strip()})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d379c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_opinions_list(assistant_response):\n",
    "    pattern = r'Q\\d\\s=\\s([\\d.,\\s]+)'\n",
    "    match = re.findall(pattern, assistant_response)\n",
    "    opinions_list = [list(map(float, values.split(', '))) for values in match]\n",
    "    return opinions_list\n",
    "\n",
    "def calculate_probability(lower_limit, upper_limit, mode):\n",
    "    if lower_limit <= mode < upper_limit:\n",
    "        return (mode - lower_limit) / ((upper_limit - lower_limit) * (mode - lower_limit))\n",
    "    elif mode == upper_limit:\n",
    "        return 1 / (upper_limit - lower_limit)\n",
    "    elif lower_limit < mode <= upper_limit:\n",
    "        return (upper_limit - mode) / ((upper_limit - lower_limit) * (upper_limit - mode))\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def calculate_probabilities_array(opinions_list):\n",
    "    # Calculate probabilities for each list\n",
    "    probabilities = []\n",
    "    for item in opinions_list:\n",
    "        lower, upper, mode = item\n",
    "        probability = calculate_probability(lower, upper, mode)\n",
    "        probabilities.append(probability)\n",
    "\n",
    "    # Normalize the probabilities to ensure they add up to 1\n",
    "    sum_probabilities = sum(probabilities)\n",
    "    normalized_probabilities = [prob / sum_probabilities for prob in probabilities]\n",
    "    complementary_probabilities = [1 - prob for prob in normalized_probabilities]\n",
    "\n",
    "    result_array = list(zip(normalized_probabilities, complementary_probabilities))\n",
    "    return result_array\n",
    "\n",
    "result_array = calculate_probabilities_array(opinions_list)\n",
    "print(result_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3002dd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"/Users/irislee/Uchicago Class Materials/4. 3Q/Capstone/Langchain/Chat\"\n",
    "file_name = \"cond_prob.json\"\n",
    "file_path = os.path.join(directory_path, file_name)\n",
    "\n",
    "# Save the Python lists to a JSON file\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(result_array, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc946f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# hedge_cpd = TabularCPD('mc', 2, result_array,\n",
    "#                         evidence=['hedge'], evidence_card=[2])\n",
    "# print(hedge_cpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e9e1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check if the matrix is acceptable based on CR\n",
    "# if CR <= 0.1:\n",
    "#     print(\"The matrix is acceptable.\")\n",
    "# else:\n",
    "#     print(\"The matrix is not acceptable.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
